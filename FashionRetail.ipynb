{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize PySpark Session\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from deep_translator import GoogleTranslator\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import  max as spark_max, row_number\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract DB from PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL_Process\") \\\n",
    "    .config(\"spark.jars\", r\"P:\\Career\\Data Engineering\\ITI-DE\\Graduation Project\\Steps\\ETL\\postgresql-42.7.5.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_url = \"jdbc:postgresql://localhost:5432/FashionRetailDB\"\n",
    "\n",
    "postgres_properties={\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"1699\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df_categories = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.categories\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_currency = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.currency\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_customers = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.customers\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_discounts = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.discounts\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_employees = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.employees\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_location = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.location\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_productattribute = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.productattribute\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_products = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.products\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_stores = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.stores\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_transactionlines = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.transactionlines\",\n",
    "    properties = postgres_properties\n",
    ")\n",
    "\n",
    "df_transactions1 = spark.read.jdbc(\n",
    "    url = postgres_url,\n",
    "    table=\"normalized_retail.transactions\",\n",
    "    properties = postgres_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ETL Process\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") #This allows Spark to parse timestamps as it did in previous versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Schema for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_schema = StructType([\n",
    "    StructField(\"Invoice ID\", StringType(), False),\n",
    "    StructField(\"Line\", IntegerType(), False),\n",
    "    StructField(\"Customer ID\", IntegerType(), True),\n",
    "    StructField(\"Product ID\", IntegerType(), True),\n",
    "    StructField(\"Size\", StringType(), True),\n",
    "    StructField(\"Color\", StringType(), True),\n",
    "    StructField(\"Unit Price\", FloatType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True),\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Discount\", FloatType(), True),\n",
    "    StructField(\"Line Total\", FloatType(), True),\n",
    "    StructField(\"Store ID\", IntegerType(), True),\n",
    "    StructField(\"Employee ID\", IntegerType(), True),\n",
    "    StructField(\"Currency\", StringType(), True),\n",
    "    StructField(\"Currency Symbol\", StringType(), True),\n",
    "    StructField(\"SKU\", StringType(), True),\n",
    "    StructField(\"Transaction Type\", StringType(), True),\n",
    "    StructField(\"Payment Method\", StringType(), True),\n",
    "    StructField(\"Invoice Total\", FloatType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DFs with schemas and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = r\"P:\\Career\\Data Engineering\\ITI-DE\\Graduation Project\\Data\\CSVs\\Transactions2.csv\"\n",
    "df_transactions2 = spark.read.option(\"header\", \"true\").schema(transactions_schema).csv(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully:\n",
    "\n",
    "1-Initialized PySpark for ETL processing.\n",
    "\n",
    "2-Extracted DB from PostgreSQL.\n",
    "\n",
    "3-Defined schema for the CSV file to avoid incorrect type inferences.\n",
    "\n",
    "4-Loaded all dataframes while ensuring structure is maintained.\n",
    "\n",
    "5-Integrated all dataframes in one dataset.\n",
    "\n",
    "6-Verified data integrity using .show()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customers Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Casting Data Types.\n",
    "\n",
    "2-Trim spaces in columns names.\n",
    "\n",
    "3-Convert emails to lowercase & remove non-numeric characters from phone numbers.\n",
    "\n",
    "4-Standardize gender values (assign \"Unknown\" if missing) & Convert date format properly.\n",
    "\n",
    "5-Filling Nulls.\n",
    "\n",
    "6-Handling Duplicates\n",
    "\n",
    "7-Fixing Emails Address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers = df_customers \\\n",
    "        .withColumnRenamed(\"customer_id\", \"Customer ID\") \\\n",
    "        .withColumnRenamed(\"locid\", \"Location ID\") \\\n",
    "        .withColumnRenamed(\"job_title\", \"Job Title\") \\\n",
    "        .withColumnRenamed(\"gender\", \"Gender\") \\\n",
    "        .withColumnRenamed(\"date_of_birth\", \"Date of Birth\") \\\n",
    "        .withColumn(\"Name\", col(\"name\")) \\\n",
    "        .withColumn(\"Email\", lower(col(\"email\"))) \\\n",
    "        .withColumn(\"Location ID\", trim(col(\"Location ID\")).cast(\"int\")) \\\n",
    "        .withColumn(\"Telephone\", regexp_replace(col(\"telephone\"), \"[^0-9]\", \"\")) \\\n",
    "        .withColumn(\"Gender\", when(upper(col(\"Gender\")) == \"M\", lit(\"M\")).when(upper(col(\"Gender\")) == \"F\", lit(\"F\")).otherwise(lit(\"U\")))        .withColumn(\"Date of Birth\", to_date(col(\"Date of Birth\"), \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----+---------+------+---------+-----------+\n",
      "|Customer ID|Name|Email|Telephone|Gender|Job Title|Location ID|\n",
      "+-----------+----+-----+---------+------+---------+-----------+\n",
      "|          0|   0|    0|        0|     0|   584185|          0|\n",
      "+-----------+----+-----+---------+------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customers.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in [\"Customer ID\", \"Name\", \"Email\", \"Telephone\", \"Gender\", \"Job Title\", \"Location ID\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers = df_customers.fillna({\"Job Title\": \"Not Specified\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----+---------+------+---------+\n",
      "|Customer ID|Name|Email|Telephone|Gender|Job Title|\n",
      "+-----------+----+-----+---------+------+---------+\n",
      "|          0|   0|    0|        0|     0|        0|\n",
      "+-----------+----+-----+---------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customers.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in [\"Customer ID\", \"Name\", \"Email\", \"Telephone\", \"Gender\", \"Job Title\"]]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_customers = df_customers.count() - df_customers.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_customers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers = df_customers.withColumn(\n",
    "    \"Email\", \n",
    "    regexp_replace(\"Email\", \"@fake.*\", \"@gmail.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customer ID',\n",
       " 'Location ID',\n",
       " 'Name',\n",
       " 'Email',\n",
       " 'Telephone',\n",
       " 'Gender',\n",
       " 'Date of Birth',\n",
       " 'Job Title']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Customer ID: integer (nullable = true)\n",
      " |-- Location ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Telephone: string (nullable = true)\n",
      " |-- Gender: string (nullable = false)\n",
      " |-- Date of Birth: date (nullable = true)\n",
      " |-- Job Title: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------+----------------+-----------+------+-------------+-------------------+\n",
      "|Customer ID|Location ID|  Name|           Email|  Telephone|Gender|Date of Birth|          Job Title|\n",
      "+-----------+-----------+------+----------------+-----------+------+-------------+-------------------+\n",
      "|     585309|         96|吴凤英|吴凤英@gmail.com|18117575105|     M|   1990-09-15|Editorial assistant|\n",
      "|     585310|         96|傅建华|傅建华@gmail.com|15660623475|     M|   2005-02-21|      Not Specified|\n",
      "|     585311|         96|  严斌|  严斌@gmail.com|15604342387|     M|   2005-10-25|      Not Specified|\n",
      "|     585312|         96|  蒋强|  蒋强@gmail.com|13143478943|     M|   2006-07-24|      Not Specified|\n",
      "|     585313|         96|李凤兰|李凤兰@gmail.com|15085275823|     F|   2005-08-11|      Not Specified|\n",
      "+-----------+-----------+------+----------------+-----------+------+-------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customers.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Casting Data Types.\n",
    "\n",
    "2-Trim spaces in columns names.\n",
    "\n",
    "3-Filling Nulls\n",
    "\n",
    "4-Handling Duplicates.\n",
    "\n",
    "5-Drop Description Columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = df_products \\\n",
    "    .withColumnRenamed(\"productid\", \"Product ID\") \\\n",
    "    .withColumnRenamed(\"categoryid\", \"Category ID\") \\\n",
    "    .withColumn(\"Product ID\", trim(col(\"Product ID\")).cast(\"int\")) \\\n",
    "    .withColumn(\"Category ID\", trim(col(\"Category ID\")).cast(\"int\")) \\\n",
    "    .withColumn(\"Description EN\", trim(col(\"Description EN\"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"Description ZH\", \"Description PT\", \"Description DE\", \"Description FR\", \"Description ES\"]\n",
    "df_products = df_products.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------+\n",
      "|Product ID|Category ID|Description EN|\n",
      "+----------+-----------+--------------+\n",
      "|         0|          0|             0|\n",
      "+----------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_products.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_products.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_products = df_products.count() - df_products.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_products}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product ID', 'Category ID', 'Description EN']"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product ID: integer (nullable = true)\n",
      " |-- Category ID: integer (nullable = true)\n",
      " |-- Description EN: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_products.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------------------+\n",
      "|Product ID|Category ID|      Description EN|\n",
      "+----------+-----------+--------------------+\n",
      "|      5006|          7|Modern Smooth Whi...|\n",
      "|      7181|         18|Women'S T-Shirt W...|\n",
      "|     13537|         10|Male Factory And ...|\n",
      "|     13149|          6|Men'S Sleep T -Sh...|\n",
      "|      3474|         14|Men'S Pants Jogge...|\n",
      "+----------+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_products.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products Attribute Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Filling Nulls\n",
    "\n",
    "3-Handling Duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_productattribute = df_productattribute \\\n",
    "        .withColumnRenamed(\"prod_attributeid\", \"Product Attribute ID\") \\\n",
    "        .withColumnRenamed(\"productid\", \"Product ID\") \\\n",
    "        .withColumnRenamed(\"color\", \"Color\") \\\n",
    "        .withColumnRenamed(\"sizes\", \"Sizes\") \\\n",
    "        .withColumnRenamed(\"productioncost\", \"Production Cost\") \\\n",
    "        .withColumnRenamed(\"sku\", \"SKU\") \\\n",
    "        .withColumn(\"Product ID\", trim(col(\"Product ID\")).cast(\"int\")) \\\n",
    "        .withColumn(\"Product Attribute ID\", trim(col(\"Product Attribute ID\")).cast(\"int\")) \\\n",
    "        .withColumn(\"Color\", trim(col(\"Color\"))) \\\n",
    "        .withColumn(\"Sizes\", trim(col(\"Sizes\"))) \\\n",
    "        .withColumn(\"Production Cost\", trim(col(\"Production Cost\")).cast(DecimalType(10,2))) \\\n",
    "        .withColumn(\"SKU\", trim(col(\"SKU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----+-----+---------------+---+\n",
      "|Product Attribute ID|Product ID|Color|Sizes|Production Cost|SKU|\n",
      "+--------------------+----------+-----+-----+---------------+---+\n",
      "|                   0|         0|    0|    0|              0|  0|\n",
      "+--------------------+----------+-----+-----+---------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_productattribute.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_productattribute.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_attribute = df_productattribute.count() - df_productattribute.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_attribute}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product Attribute ID',\n",
       " 'Product ID',\n",
       " 'Color',\n",
       " 'Sizes',\n",
       " 'Production Cost',\n",
       " 'SKU']"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_productattribute.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Product Attribute ID: integer (nullable = true)\n",
      " |-- Product ID: integer (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Sizes: string (nullable = true)\n",
      " |-- Production Cost: decimal(10,2) (nullable = true)\n",
      " |-- SKU: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_productattribute.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+----------+---------------+--------------------+\n",
      "|Product Attribute ID|Product ID|  Color|     Sizes|Production Cost|                 SKU|\n",
      "+--------------------+----------+-------+----------+---------------+--------------------+\n",
      "|                   1|      8151|NEUTRAL|M|L|XL|XXL|          22.28|MASW8151-XXL-NEUTRAL|\n",
      "|                   2|     14054|   BLUE|M|L|XL|XXL|          11.69|  MAT-14054-XXL-BLUE|\n",
      "|                   3|     15052|   BLUE|     P|M|G|          11.00|    CHSW15052-P-BLUE|\n",
      "|                   4|     13131|    RED|  S|M|L|XL|          30.16|     FECO13131-S-RED|\n",
      "|                   5|     11722|  BEIGE|  P|M|G|GG|           7.64|   CHGI11722-G-BEIGE|\n",
      "+--------------------+----------+-------+----------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_productattribute.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employees Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Filling Nulls\n",
    "\n",
    "3-Handling Duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_employees = df_employees \\\n",
    "            .withColumnRenamed(\"employeeid\", \"employeeid_pk_bk\") \\\n",
    "            .withColumn(\"name\", trim(col(\"name\"))) \\\n",
    "            .withColumn(\"position\", trim(col(\"position\"))) \\\n",
    "            .withColumn(\"employeeid_pk_bk\", col(\"employeeid_pk_bk\").cast(\"int\")) \\\n",
    "            .withColumn(\"storeid\", col(\"storeid\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+--------+-------+\n",
      "|employeeid_pk_bk|name|position|storeid|\n",
      "+----------------+----+--------+-------+\n",
      "|               0|   0|       0|      0|\n",
      "+----------------+----+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employees.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_employees.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_employees = df_employees.count() - df_employees.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_employees}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['employeeid_pk_bk', 'name', 'position', 'storeid']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_employees.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employeeid_pk_bk: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      " |-- storeid: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employees.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+-----------------+-------+\n",
      "|employeeid_pk_bk|           name|         position|storeid|\n",
      "+----------------+---------------+-----------------+-------+\n",
      "|               1|   DRAGO HORNIG|ASSISTANT MANAGER|     11|\n",
      "|               2|   NOAH AZEVEDO|      STOCK CLERK|     31|\n",
      "|               3|    JOHN BAILEY|          CASHIER|     20|\n",
      "|               4|           唐旭|  SALES ASSOCIATE|      7|\n",
      "|               5|LOURDES CABAÑAS|  SALES ASSOCIATE|     26|\n",
      "+----------------+---------------+-----------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_employees.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currency Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Drop Currency Symbol Column.\n",
    "\n",
    "3-Filling Nulls\n",
    "\n",
    "4-Handling Duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_currency = df_currency \\\n",
    "            .withColumnRenamed(\"currencyid\", \"Currency ID\") \\\n",
    "            .withColumnRenamed(\"currency\", \"Currency\") \\\n",
    "            .withColumn(\"Currency\", trim(col(\"Currency\"))) \\\n",
    "            .withColumn(\"Currency ID\", col(\"Currency ID\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_currency = df_currency.drop(\"currencysymbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|Currency ID|Currency|\n",
      "+-----------+--------+\n",
      "|          0|       0|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_currency.select([count(when(col(c).isNull(), c)).alias(c) for c in df_currency.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_currency = df_currency.count() - df_currency.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_currency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Currency ID', 'Currency']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_currency.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Currency ID: integer (nullable = true)\n",
      " |-- Currency: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_currency.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|Currency ID|Currency|\n",
      "+-----------+--------+\n",
      "|          1|     USD|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_currency.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Filling Nulls\n",
    "\n",
    "3-Handling Duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_location = df_location \\\n",
    "        .withColumnRenamed(\"locid\", \"Location ID\") \\\n",
    "        .withColumnRenamed(\"city\", \"City\") \\\n",
    "        .withColumnRenamed(\"country\", \"Country\") \\\n",
    "        .withColumn(\"City\", trim(col(\"City\"))) \\\n",
    "        .withColumn(\"Country\", trim(col(\"Country\"))) \\\n",
    "        .withColumn(\"Location ID\", col(\"Location ID\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-------+\n",
      "|Location ID|City|Country|\n",
      "+-----------+----+-------+\n",
      "|          0|   0|      0|\n",
      "+-----------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_location.select([count(when(col(c).isNull(), c)).alias(c) for c in df_location.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_location = df_location.count() - df_location.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Location ID', 'City', 'Country']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_location.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Location ID: integer (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_location.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------+\n",
      "|Location ID|     City|      Country|\n",
      "+-----------+---------+-------------+\n",
      "|          1| Oak Park|United States|\n",
      "|          2|     Haan|  Deutschland|\n",
      "|          3| Juvignac|       France|\n",
      "|          4|Colomiers|       France|\n",
      "|          5|   Quincy|United States|\n",
      "+-----------+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_location.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categories Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Filling Nulls\n",
    "\n",
    "3-Handling Duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories = df_categories \\\n",
    "        .withColumn(\"category\", trim(col(\"category\"))) \\\n",
    "        .withColumn(\"subcategory\", trim(col(\"subcategory\"))) \\\n",
    "        .withColumnRenamed(\"categoryid\", \"Category ID\") \\\n",
    "        .withColumnRenamed(\"category\", \"Category\") \\\n",
    "        .withColumnRenamed(\"subcategory\", \"SubCategory\") \\\n",
    "        .withColumn(\"Category ID\", col(\"Category ID\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-----------+\n",
      "|Category ID|Category|SubCategory|\n",
      "+-----------+--------+-----------+\n",
      "|          0|       0|          0|\n",
      "+-----------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_categories.select([count(when(col(c).isNull(), c)).alias(c) for c in df_categories.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_category = df_categories.count() - df_categories.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Category ID', 'Category', 'SubCategory']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Category ID: integer (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- SubCategory: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_categories.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---------------+\n",
      "|Category ID|Category|    SubCategory|\n",
      "+-----------+--------+---------------+\n",
      "|          1|FEMININE|     SPORTSWEAR|\n",
      "|          2|CHILDREN|        PAJAMAS|\n",
      "|          3|FEMININE|PANTS AND JEANS|\n",
      "|          4|CHILDREN|          COATS|\n",
      "|          5|FEMININE| SUITS AND SETS|\n",
      "+-----------+--------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_categories.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stores Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Filling Nulls\n",
    "\n",
    "3-Handling Duplicates.\n",
    "\n",
    "4-Translate Store Names into English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stores = df_stores \\\n",
    "        .withColumnRenamed(\"storename\", \"Store Name\") \\\n",
    "        .withColumnRenamed(\"zipcode\", \"Zip Code\") \\\n",
    "        .withColumnRenamed(\"storeid\", \"Store ID\") \\\n",
    "        .withColumnRenamed(\"latitude\", \"Latitude\") \\\n",
    "        .withColumnRenamed(\"longitude\", \"Longitude\") \\\n",
    "        .withColumnRenamed(\"locid\", \"Location ID\") \\\n",
    "        .withColumnRenamed(\"numberofemployees\", \"Number of Employees\") \\\n",
    "        .withColumnRenamed(\"zipcode\", \"Zip Code\") \\\n",
    "        .withColumn(\"Store Name\", trim(col(\"Store Name\"))) \\\n",
    "        .withColumn(\"Zip Code\", trim(col(\"Zip Code\"))) \\\n",
    "        .withColumn(\"Store ID\", col(\"Store ID\").cast(\"int\")) \\\n",
    "        .withColumn(\"Location ID\", col(\"Location ID\").cast(\"int\")) \\\n",
    "        .withColumn(\"Number of Employees\", col(\"Number of Employees\").cast(\"int\")) \\\n",
    "        .withColumn(\"Latitude\", col(\"Latitude\").cast(DecimalType(10,6))) \\\n",
    "        .withColumn(\"Longitude\", col(\"Longitude\").cast(DecimalType(10,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+-------------------+--------+--------+---------+\n",
      "|Store ID|Location ID|Store Name|Number of Employees|Zip Code|Latitude|Longitude|\n",
      "+--------+-----------+----------+-------------------+--------+--------+---------+\n",
      "|       0|          0|         0|                  0|       0|       0|        0|\n",
      "+--------+-----------+----------+-------------------+--------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stores.select([count(when(col(c).isNull(), c)).alias(c) for c in df_stores.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_stores = df_stores.count() - df_stores.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_stores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Store ID',\n",
       " 'Location ID',\n",
       " 'Store Name',\n",
       " 'Number of Employees',\n",
       " 'Zip Code',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Store ID: integer (nullable = true)\n",
      " |-- Location ID: integer (nullable = true)\n",
      " |-- Store Name: string (nullable = true)\n",
      " |-- Number of Employees: integer (nullable = true)\n",
      " |-- Zip Code: string (nullable = true)\n",
      " |-- Latitude: decimal(10,6) (nullable = true)\n",
      " |-- Longitude: decimal(10,6) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stores.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------------+-------------------+--------+---------+-----------+\n",
      "|Store ID|Location ID|      Store Name|Number of Employees|Zip Code| Latitude|  Longitude|\n",
      "+--------+-----------+----------------+-------------------+--------+---------+-----------+\n",
      "|       1|        636|STORE BIRMINGHAM|                  9|  B1 1AA|52.486200|  -1.890400|\n",
      "|       2|        483| STORE GUIMARÃES|                  9|4800-001|41.444400|  -8.296200|\n",
      "|       3|         79|  STORE ZARAGOZA|                  9|   50001|41.641900|  -0.904600|\n",
      "|       4|         29|   STORE BRISTOL|                  7| BS1 1AA|51.454500|  -2.587900|\n",
      "|       5|        668|   STORE PHOENIX|                  9|   85001|33.448400|-112.074000|\n",
      "+--------+-----------+----------------+-------------------+--------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stores.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discounts Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Filling Nulls\n",
    "\n",
    "3-Handling Duplicates.\n",
    "\n",
    "4-Drop Description Column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discounts = df_discounts \\\n",
    "        .withColumn(\"discountid\", trim(col(\"discountid\")).cast(\"int\")) \\\n",
    "        .withColumn(\"categoryid\", trim(col(\"categoryid\")).cast(\"int\")) \\\n",
    "        .withColumn(\"Start\", to_date(trim(col(\"Start\")), \"yyyy-MM-dd\")) \\\n",
    "        .withColumn(\"End\", to_date(trim(col(\"End\")), \"yyyy-MM-dd\")) \\\n",
    "        .withColumn(\"discount\", trim(col(\"discount\")).cast(DecimalType(5,2))) \\\n",
    "        .withColumn(\"description\", trim(col(\"description\"))) \\\n",
    "        .withColumnRenamed(\"discountid\", \"Discount ID\") \\\n",
    "        .withColumnRenamed(\"categoryid\", \"Category ID\") \\\n",
    "        .withColumnRenamed(\"Start\", \"Start Date\") \\\n",
    "        .withColumnRenamed(\"End\", \"End Date\") \\\n",
    "        .withColumnRenamed(\"Discount\", \"Discount\") \\\n",
    "        .withColumnRenamed(\"Description\", \"Description\")                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+--------+-----------+-----------+\n",
      "|Discount ID|Start Date|End Date|Discount|Description|Category ID|\n",
      "+-----------+----------+--------+--------+-----------+-----------+\n",
      "|          0|         0|       0|       0|          0|          0|\n",
      "+-----------+----------+--------+--------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_discounts.select([count(when(col(c).isNull(), c)).alias(c) for c in df_discounts.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_discounts = df_discounts.count() - df_discounts.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_discounts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"Description\"]\n",
    "df_discounts = df_discounts.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Discount ID', 'Start Date', 'End Date', 'Discount', 'Category ID']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_discounts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Discount ID: integer (nullable = true)\n",
      " |-- Start Date: date (nullable = true)\n",
      " |-- End Date: date (nullable = true)\n",
      " |-- Discount: decimal(5,2) (nullable = true)\n",
      " |-- Category ID: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_discounts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+--------+-----------+\n",
      "|Discount ID|Start Date|  End Date|Discount|Category ID|\n",
      "+-----------+----------+----------+--------+-----------+\n",
      "|          1|2024-10-01|2024-10-10|    0.20|         22|\n",
      "|          2|2020-09-01|2020-09-15|    0.45|         21|\n",
      "|          3|2024-05-01|2024-05-15|    0.25|         14|\n",
      "|          4|2022-10-01|2022-10-10|    0.20|         15|\n",
      "|          5|2020-01-01|2020-01-10|    0.40|         17|\n",
      "+-----------+----------+----------+--------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_discounts.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transactions Table (CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Drop unnecessary columns that won't be used in dwh.\n",
    "\n",
    "3-Drop Currency Symbol Column.\n",
    "\n",
    "4-Filling Nulls\n",
    "\n",
    "5-Handling Duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactionscsv = df_transactions2 \\\n",
    "    .withColumn(\"Invoice ID\", F.col(\"Invoice ID\").cast(StringType())) \\\n",
    "    .withColumn(\"Line\", F.col(\"Line\").cast(IntegerType())) \\\n",
    "    .withColumn(\"Customer ID\", F.col(\"Customer ID\").cast(StringType())) \\\n",
    "    .withColumn(\"Product ID\", F.col(\"Product ID\").cast(StringType())) \\\n",
    "    .withColumn(\"Size\", F.col(\"Size\").cast(StringType())) \\\n",
    "    .withColumn(\"Color\", F.col(\"Color\").cast(StringType())) \\\n",
    "    .withColumn(\"Unit Price\", F.col(\"Unit Price\").cast(DoubleType())) \\\n",
    "    .withColumn(\"Quantity\", F.col(\"Quantity\").cast(IntegerType())) \\\n",
    "    .withColumn(\"Date\", F.to_timestamp(F.col(\"Date\"), \"dd/MM/yyyy HH:mm\").cast(TimestampType())) \\\n",
    "    .withColumn(\"Discount\", F.col(\"Discount\").cast(DoubleType())) \\\n",
    "    .withColumn(\"Line Total\", F.col(\"Line Total\").cast(DecimalType(10,2))) \\\n",
    "    .withColumn(\"Store ID\", F.col(\"Store ID\").cast(StringType())) \\\n",
    "    .withColumn(\"Employee ID\", F.col(\"Employee ID\").cast(StringType())) \\\n",
    "    .withColumn(\"Currency\", F.col(\"Currency\").cast(StringType())) \\\n",
    "    .withColumn(\"Currency Symbol\", F.col(\"Currency Symbol\").cast(StringType())) \\\n",
    "    .withColumn(\"SKU\", F.col(\"SKU\").cast(StringType())) \\\n",
    "    .withColumn(\"Transaction Type\", F.col(\"Transaction Type\").cast(StringType())) \\\n",
    "    .withColumn(\"Payment Method\", F.col(\"Payment Method\").cast(StringType())) \\\n",
    "    .withColumn(\"Invoice Total\", F.col(\"Invoice Total\").cast(DecimalType(10,2)))\\\n",
    "    .drop(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactionscsv = df_transactionscsv.drop(\"Currency Symbol\", 'Customer ID',\n",
    "        'Product ID','SKU','Size','Color',\n",
    "        'Store ID','Employee ID','Currency',\n",
    "        'Unit Price','Discount',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------+----------+----------------+--------------+-------------+\n",
      "|Invoice ID|Line|Quantity|Line Total|Transaction Type|Payment Method|Invoice Total|\n",
      "+----------+----+--------+----------+----------------+--------------+-------------+\n",
      "|         0|   0|       0|         0|               0|             0|            0|\n",
      "+----------+----+--------+----------+----------------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionscsv.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_transactionscsv.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 1002\n"
     ]
    }
   ],
   "source": [
    "duplicates_count = df_transactionscsv.count() - df_transactionscsv.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicates_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactionscsv = df_transactionscsv.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates_count = df_transactionscsv.count() - df_transactionscsv.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicates_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Invoice ID',\n",
       " 'Line',\n",
       " 'Quantity',\n",
       " 'Line Total',\n",
       " 'Transaction Type',\n",
       " 'Payment Method',\n",
       " 'Invoice Total']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactionscsv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Invoice ID: string (nullable = true)\n",
      " |-- Line: integer (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Line Total: decimal(10,2) (nullable = true)\n",
      " |-- Transaction Type: string (nullable = true)\n",
      " |-- Payment Method: string (nullable = true)\n",
      " |-- Invoice Total: decimal(10,2) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionscsv.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+--------+----------+----------------+--------------+-------------+\n",
      "|         Invoice ID|Line|Quantity|Line Total|Transaction Type|Payment Method|Invoice Total|\n",
      "+-------------------+----+--------+----------+----------------+--------------+-------------+\n",
      "|INV-US-004-01360435|   1|       1|    138.50|            Sale|   Credit Card|       138.50|\n",
      "|INV-US-004-01361037|   1|       1|     62.50|            Sale|   Credit Card|        62.50|\n",
      "|INV-US-004-01361071|   1|       1|     76.00|            Sale|   Credit Card|        76.00|\n",
      "|INV-US-004-01361149|   4|       1|     33.00|            Sale|   Credit Card|       326.00|\n",
      "|INV-US-004-01361556|   2|       1|     32.50|            Sale|          Cash|       241.50|\n",
      "+-------------------+----+--------+----------+----------------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionscsv.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transactions Table (DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Drop unnecessary columns that won't be used in dwh.\n",
    "\n",
    "3-Drop Currency Symbol Column.\n",
    "\n",
    "4-Filling Nulls\n",
    "\n",
    "5-Handling Duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactionsdb = df_transactions1 \\\n",
    "    .withColumnRenamed(\"transactionid\", \"Transaction ID\") \\\n",
    "    .withColumnRenamed(\"invoiceid\", \"Invoice ID\") \\\n",
    "    .withColumnRenamed(\"transactiondate\", \"Transaction Date\") \\\n",
    "    .withColumnRenamed(\"transactiontype\", \"Transaction Type\") \\\n",
    "    .withColumnRenamed(\"discountid\", \"Discount ID\") \\\n",
    "    .withColumnRenamed(\"paymentmethod\", \"Payment Method\") \\\n",
    "    .withColumnRenamed(\"invoicetotal\", \"Invoice Total\") \\\n",
    "    .withColumnRenamed(\"customerid\", \"Customer ID\") \\\n",
    "    .withColumnRenamed(\"storeid\", \"Store ID\") \\\n",
    "    .withColumnRenamed(\"employeeid\", \"Employee ID\") \\\n",
    "    .withColumnRenamed(\"currencyid\", \"Currency ID\") \\\n",
    "    .withColumn(\"Transaction ID\", trim(col(\"Transaction ID\")).cast(\"int\")) \\\n",
    "    .withColumn(\"Invoice ID\", trim(col(\"Invoice ID\")).cast(\"string\")) \\\n",
    "    .withColumn(\"Transaction Date\", trim(col(\"Transaction Date\")).cast(\"timestamp\")) \\\n",
    "    .withColumn(\"Transaction Type\", trim(col(\"Transaction Type\")).cast(\"string\")) \\\n",
    "    .withColumn(\"Discount ID\", trim(col(\"Discount ID\")).cast(\"double\")) \\\n",
    "    .withColumn(\"Payment Method\", trim(col(\"Payment Method\")).cast(\"string\")) \\\n",
    "    .withColumn(\"Invoice Total\", trim(col(\"Invoice Total\")).cast(DecimalType(10,2))) \\\n",
    "    .withColumn(\"Customer ID\", trim(col(\"Customer ID\")).cast(\"int\")) \\\n",
    "    .withColumn(\"Store ID\", trim(col(\"Store ID\")).cast(\"int\")) \\\n",
    "    .withColumn(\"Employee ID\", trim(col(\"Employee ID\")).cast(\"int\")) \\\n",
    "    .withColumn(\"Currency ID\", trim(col(\"Currency ID\")).cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transaction ID',\n",
       " 'Invoice ID',\n",
       " 'Transaction Date',\n",
       " 'Transaction Type',\n",
       " 'Discount ID',\n",
       " 'Payment Method',\n",
       " 'Invoice Total',\n",
       " 'Customer ID',\n",
       " 'Store ID',\n",
       " 'Employee ID',\n",
       " 'Currency ID']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactionsdb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactionsdb = df_transactionsdb.drop('Customer ID', 'Store ID','Employee ID','Currency ID','Discount ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transaction ID',\n",
       " 'Invoice ID',\n",
       " 'Transaction Date',\n",
       " 'Transaction Type',\n",
       " 'Payment Method',\n",
       " 'Invoice Total']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactionsdb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+----------------+----------------+--------------+-------------+\n",
      "|Transaction ID|Invoice ID|Transaction Date|Transaction Type|Payment Method|Invoice Total|\n",
      "+--------------+----------+----------------+----------------+--------------+-------------+\n",
      "|             0|         0|               0|               0|             0|            0|\n",
      "+--------------+----------+----------------+----------------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionsdb.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df_transactionsdb.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates_count = df_transactionsdb.count() - df_transactionsdb.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicates_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transaction ID',\n",
       " 'Invoice ID',\n",
       " 'Transaction Date',\n",
       " 'Transaction Type',\n",
       " 'Payment Method',\n",
       " 'Invoice Total']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactionsdb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Transaction ID: integer (nullable = true)\n",
      " |-- Invoice ID: string (nullable = true)\n",
      " |-- Transaction Date: timestamp (nullable = true)\n",
      " |-- Transaction Type: string (nullable = true)\n",
      " |-- Payment Method: string (nullable = true)\n",
      " |-- Invoice Total: decimal(10,2) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionsdb.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------------+----------------+--------------+-------------+\n",
      "|Transaction ID|         Invoice ID|   Transaction Date|Transaction Type|Payment Method|Invoice Total|\n",
      "+--------------+-------------------+-------------------+----------------+--------------+-------------+\n",
      "|        435821|INV-US-001-03650258|2023-10-04 19:28:00|            Sale|   Credit Card|        50.00|\n",
      "|        435822|INV-US-001-03650259|2023-10-04 08:59:00|            Sale|   Credit Card|        27.50|\n",
      "|        435823|INV-US-001-03650260|2023-10-04 11:50:00|            Sale|   Credit Card|        95.40|\n",
      "|        435824|INV-US-001-03650260|2023-10-04 11:50:00|            Sale|   Credit Card|        95.40|\n",
      "|        435825|INV-US-001-03650261|2023-10-04 16:26:00|            Sale|   Credit Card|        64.40|\n",
      "+--------------+-------------------+-------------------+----------------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionsdb.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transaction Lines Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Trim Spaces & Cast Data Types.\n",
    "\n",
    "2-Filling Nulls\n",
    "\n",
    "3-Handling Duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactionlines = df_transactionlines \\\n",
    "        .withColumnRenamed(\"transactionlineid\", \"Transaction Line ID\") \\\n",
    "        .withColumnRenamed(\"transactionid\", \"Transaction ID\") \\\n",
    "        .withColumnRenamed(\"productid\", \"Product ID\") \\\n",
    "        .withColumnRenamed(\"unitprice\", \"Unit Price\") \\\n",
    "        .withColumnRenamed(\"quantity\", \"Quantity\") \\\n",
    "        .withColumnRenamed(\"discount\", \"Discount\") \\\n",
    "        .withColumnRenamed(\"linetotal\", \"Line Total\") \\\n",
    "        .withColumnRenamed(\"line\", \"Line\") \\\n",
    "        .withColumn(\"Transaction ID\", trim(col(\"Transaction ID\")).cast(\"int\")) \\\n",
    "        .withColumn(\"Transaction Line ID\", trim(col(\"Transaction Line ID\")).cast(\"int\")) \\\n",
    "        .withColumn(\"Product ID\", trim(col(\"Product ID\"))) \\\n",
    "        .withColumn(\"Unit Price\", trim(col(\"Unit Price\")).cast(DecimalType(10,2))) \\\n",
    "        .withColumn(\"Quantity\", trim(col(\"Quantity\")).cast(\"int\")) \\\n",
    "        .withColumn(\"line\", trim(col(\"line\")).cast(\"int\")) \\\n",
    "        .withColumn(\"Discount\", trim(col(\"Discount\")).cast(\"double\")) \\\n",
    "        .withColumn(\"Line Total\", trim(col(\"Line Total\")).cast(DecimalType(10,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+----------+----------+--------+--------+----------+----+\n",
      "|Transaction Line ID|Transaction ID|Product ID|Unit Price|Quantity|Discount|Line Total|line|\n",
      "+-------------------+--------------+----------+----------+--------+--------+----------+----+\n",
      "|                  0|             0|         0|         0|       0|       0|         0|   0|\n",
      "+-------------------+--------------+----------+----------+--------+--------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionlines.select([count(when(col(c).isNull(), c)).alias(c) for c in df_transactionlines.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "duplicate_count_lines = df_transactionlines.count() - df_transactionlines.dropDuplicates().count()\n",
    "print(f\"Number of duplicate rows: {duplicate_count_lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transaction Line ID',\n",
       " 'Transaction ID',\n",
       " 'Product ID',\n",
       " 'Unit Price',\n",
       " 'Quantity',\n",
       " 'Discount',\n",
       " 'Line Total',\n",
       " 'line']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactionlines.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Transaction Line ID: integer (nullable = true)\n",
      " |-- Transaction ID: integer (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Unit Price: decimal(10,2) (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Discount: double (nullable = true)\n",
      " |-- Line Total: decimal(10,2) (nullable = true)\n",
      " |-- line: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionlines.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+----------+----------+--------+--------+----------+----+\n",
      "|Transaction Line ID|Transaction ID|Product ID|Unit Price|Quantity|Discount|Line Total|line|\n",
      "+-------------------+--------------+----------+----------+--------+--------+----------+----+\n",
      "|             487884|       1054491|     11960|      8.00|       1|     0.0|      8.00|   4|\n",
      "|             487885|       1054491|      9950|     49.00|       1|     0.0|     49.00|   3|\n",
      "|             487886|       1054491|     11312|     35.50|       1|     0.0|     35.50|   2|\n",
      "|             487887|       1054491|      9231|     53.50|       1|     0.0|     53.50|   1|\n",
      "|             487888|       1054493|     10094|     78.00|       1|     0.0|     78.00|   1|\n",
      "+-------------------+--------------+----------+----------+--------+--------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionlines.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining DWH Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customers Table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Customers & Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_dwh = df_customers.join(df_location, \"Location ID\", \"left\")\n",
    "\n",
    "windowSpec = Window.orderBy(\"Customer ID\")\n",
    "\n",
    "customers_dwh = customers_dwh.select(\n",
    "    row_number().over(windowSpec).alias(\"customerid_pk_sk\"),\n",
    "    df_customers[\"Customer ID\"].alias(\"customerid_pk_bk\"),\n",
    "    df_customers[\"Name\"].alias(\"name\"),\n",
    "    df_customers[\"Email\"].alias(\"email\"),\n",
    "    df_customers[\"Telephone\"].alias(\"telephone\"),\n",
    "    df_location[\"City\"].alias(\"city\"),\n",
    "    df_location[\"Country\"].alias(\"country\"),\n",
    "    df_customers[\"Gender\"].alias(\"gender\"),\n",
    "    df_customers[\"Date of Birth\"].alias(\"date_of_birth\"),\n",
    "    df_customers[\"Job Title\"].alias(\"job_title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-------------------+--------------------+---------------+--------+-------------+------+-------------+--------------------+\n",
      "|customerid_pk_sk|customerid_pk_bk|               name|               email|      telephone|    city|      country|gender|date_of_birth|           job_title|\n",
      "+----------------+----------------+-------------------+--------------------+---------------+--------+-------------+------+-------------+--------------------+\n",
      "|               1|               1|       Tyler Garcia|tyler.garcia@gmai...|922970226547563|New York|United States|     M|   2003-07-15|       Not Specified|\n",
      "|               2|               2|      Joshua Miller|joshua.miller@gma...|    19587296169|New York|United States|     M|   2000-06-16|     Records manager|\n",
      "|               3|               3|Alison Marshall DDS|alison.marshall.d...|164556708765409|New York|United States|     F|   2003-07-22|       Not Specified|\n",
      "|               4|               4|     Jeffery Acosta|jeffery.acosta@gm...|212336091284994|New York|United States|     M|   1996-11-12|         Proofreader|\n",
      "|               5|               5|     Ashley Sanders|ashley.sanders@gm...|     7814535781|New York|United States|     F|   1998-02-10|Exercise physiolo...|\n",
      "+----------------+----------------+-------------------+--------------------+---------------+--------+-------------+------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_dwh.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerid_pk_sk: integer (nullable = false)\n",
      " |-- customerid_pk_bk: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- telephone: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- job_title: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_dwh.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discounts Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Discounts & Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Description column is dropped before. (unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "discounts_dwh = df_discounts.join(df_categories, \"Category ID\", \"left\")\n",
    "\n",
    "windowSpec = Window.orderBy(\"Discount ID\")\n",
    "\n",
    "discounts_dwh = discounts_dwh.select(\n",
    "    row_number().over(windowSpec).alias(\"discountid_pk_sk\"),\n",
    "    df_discounts[\"Discount ID\"].alias(\"discountid_pk_bk\"),\n",
    "    df_discounts[\"Start Date\"].alias(\"startdate\"),\n",
    "    df_discounts[\"End Date\"].alias(\"enddate\"),\n",
    "    df_discounts[\"Discount\"].alias(\"discount\"),\n",
    "    df_categories[\"Category\"].alias(\"category\"),\n",
    "    df_categories[\"SubCategory\"].alias(\"subcategory\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+----------+----------+--------+---------+--------------------+\n",
      "|discountid_pk_sk|discountid_pk_bk| startdate|   enddate|discount| category|         subcategory|\n",
      "+----------------+----------------+----------+----------+--------+---------+--------------------+\n",
      "|               1|               1|2024-10-01|2024-10-10|    0.20| FEMININE|SWEATERS AND KNIT...|\n",
      "|               2|               2|2020-09-01|2020-09-15|    0.45|MASCULINE|              SHIRTS|\n",
      "|               3|               3|2024-05-01|2024-05-15|    0.25|MASCULINE|     PANTS AND JEANS|\n",
      "|               4|               4|2022-10-01|2022-10-10|    0.20|MASCULINE|          SPORTSWEAR|\n",
      "|               5|               5|2020-01-01|2020-01-10|    0.40| CHILDREN|            SWEATERS|\n",
      "+----------------+----------------+----------+----------+--------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "discounts_dwh.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- discountid_pk_sk: integer (nullable = false)\n",
      " |-- discountid_pk_bk: integer (nullable = true)\n",
      " |-- startdate: date (nullable = true)\n",
      " |-- enddate: date (nullable = true)\n",
      " |-- discount: decimal(5,2) (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- subcategory: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "discounts_dwh.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Categories, Products & Products Attribute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Description columns in other languages except English & Currency Symbol are drooped. (Unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number, lit, col\n",
    "\n",
    "# Step 1: Join products with categories to get category information\n",
    "prod_with_cat = df_products.join(\n",
    "    df_categories,\n",
    "    \"Category ID\",\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Step 2: Join with transaction lines to get unit price (take the first available price)\n",
    "prod_with_price = prod_with_cat.join(\n",
    "    df_transactionlines,\n",
    "    \"Product ID\",\n",
    "    \"left\"\n",
    ").groupBy(\n",
    "    \"Product ID\", \"Category\", \"SubCategory\", \"Description EN\"\n",
    ").agg(\n",
    "    {\"Unit Price\": \"first\"}  # Takes the first available price\n",
    ").withColumnRenamed(\"first(Unit Price)\", \"Unit Price\")\n",
    "\n",
    "# Step 3: Join with product attributes (ensure proper join)\n",
    "products_dwh_temp = prod_with_price.join(\n",
    "    df_productattribute.alias(\"attr\"),\n",
    "    \"Product ID\",\n",
    "    \"left\"\n",
    ").select(\n",
    "    col(\"Product ID\"),\n",
    "    col(\"Unit Price\"),\n",
    "    col(\"Category\"),\n",
    "    col(\"SubCategory\"),\n",
    "    col(\"Description EN\"),\n",
    "    col(\"attr.Color\"),\n",
    "    col(\"attr.Sizes\"),\n",
    "    col(\"attr.Production Cost\"),\n",
    "    col(\"attr.SKU\")\n",
    ")\n",
    "\n",
    "# Step 4: Add surrogate key and currency\n",
    "windowSpec = Window.orderBy(\"Product ID\")\n",
    "products_dwh = products_dwh_temp.select(\n",
    "    row_number().over(windowSpec).alias(\"productid_pk_sk\"),\n",
    "    col(\"Product ID\").alias(\"productid_pk_bk\"),\n",
    "    col(\"Category\").alias(\"category\"),\n",
    "    col(\"SubCategory\").alias(\"subcategory\"),\n",
    "    col(\"Description EN\").alias(\"descriptionen\"),\n",
    "    coalesce(col(\"Color\"), lit(\"N/A\")).alias(\"color\"),\n",
    "    coalesce(col(\"Sizes\"), lit(\"UNKNOWN\")).alias(\"sizes\"),\n",
    "    coalesce(col(\"Production Cost\"), lit(0.0)).alias(\"productioncost\"),\n",
    "    coalesce(col(\"SKU\"), lit(\"NO_SKU\")).alias(\"sku\"),\n",
    "    lit(\"USD\").alias(\"Currency\"),    \n",
    "    coalesce(col(\"Unit Price\"), lit(0.0)).alias(\"unitprice\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+--------+--------------------+--------------------+-----+--------+--------------+-------------+--------+---------+\n",
      "|productid_pk_sk|productid_pk_bk|category|         subcategory|       descriptionen|color|   sizes|productioncost|          sku|Currency|unitprice|\n",
      "+---------------+---------------+--------+--------------------+--------------------+-----+--------+--------------+-------------+--------+---------+\n",
      "|              1|              1|FEMININE|   COATS AND BLAZERS|Sports Velvet Spo...|  N/A| UNKNOWN|           0.0|       NO_SKU|     USD|     72.0|\n",
      "|              2|              2|FEMININE|SWEATERS AND KNIT...|Luxurious Pink De...| PINK|S|M|L|XL|         19.55| FESW2-S-PINK|     USD|     40.0|\n",
      "|              3|              2|FEMININE|SWEATERS AND KNIT...|Luxurious Pink De...| PINK|S|M|L|XL|         19.55|FESW2-XL-PINK|     USD|     40.0|\n",
      "|              4|              2|FEMININE|SWEATERS AND KNIT...|Luxurious Pink De...| PINK|S|M|L|XL|         19.55| FESW2-L-PINK|     USD|     40.0|\n",
      "|              5|              2|FEMININE|SWEATERS AND KNIT...|Luxurious Pink De...| PINK|S|M|L|XL|         19.55| FESW2-M-PINK|     USD|     40.0|\n",
      "+---------------+---------------+--------+--------------------+--------------------+-----+--------+--------------+-------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_dwh.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- productid_pk_sk: integer (nullable = false)\n",
      " |-- productid_pk_bk: integer (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- subcategory: string (nullable = true)\n",
      " |-- descriptionen: string (nullable = true)\n",
      " |-- color: string (nullable = false)\n",
      " |-- sizes: string (nullable = false)\n",
      " |-- productioncost: double (nullable = false)\n",
      " |-- sku: string (nullable = false)\n",
      " |-- Currency: string (nullable = false)\n",
      " |-- unitprice: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_dwh.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stores Table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Stores & Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_dwh = df_stores.join(df_location, \"Location ID\", \"left\")\n",
    "\n",
    "windowSpec = Window.orderBy(\"Store ID\")\n",
    "\n",
    "stores_dwh = stores_dwh.select(\n",
    "    row_number().over(windowSpec).alias(\"storeid_pk_sk\"),\n",
    "    df_stores[\"Store ID\"].alias(\"storeid_pk_bk\"),   \n",
    "    df_location[\"Country\"].alias(\"country\"), \n",
    "    df_location[\"City\"].alias(\"city\"),\n",
    "    df_stores[\"Store Name\"].alias(\"storename\"),\n",
    "    df_stores[\"Number of Employees\"].alias(\"numberofemployees\"),\n",
    "    df_stores[\"Zip Code\"].alias(\"zipcode\"),\n",
    "    df_stores[\"Latitude\"].alias(\"latitude\"),\n",
    "    df_stores[\"Longitude\"].alias(\"longitude\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+--------------+----------+----------------+-----------------+--------+---------+-----------+\n",
      "|storeid_pk_sk|storeid_pk_bk|       country|      city|       storename|numberofemployees| zipcode| latitude|  longitude|\n",
      "+-------------+-------------+--------------+----------+----------------+-----------------+--------+---------+-----------+\n",
      "|            1|            1|United Kingdom|Birmingham|STORE BIRMINGHAM|                9|  B1 1AA|52.486200|  -1.890400|\n",
      "|            2|            2|      Portugal| Guimarães| STORE GUIMARÃES|                9|4800-001|41.444400|  -8.296200|\n",
      "|            3|            3|        España|  Zaragoza|  STORE ZARAGOZA|                9|   50001|41.641900|  -0.904600|\n",
      "|            4|            4|United Kingdom|   Bristol|   STORE BRISTOL|                7| BS1 1AA|51.454500|  -2.587900|\n",
      "|            5|            5| United States|   Phoenix|   STORE PHOENIX|                9|   85001|33.448400|-112.074000|\n",
      "+-------------+-------------+--------------+----------+----------------+-----------------+--------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stores_dwh.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- storeid_pk_sk: integer (nullable = false)\n",
      " |-- storeid_pk_bk: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- storename: string (nullable = true)\n",
      " |-- numberofemployees: integer (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      " |-- latitude: decimal(10,6) (nullable = true)\n",
      " |-- longitude: decimal(10,6) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stores_dwh.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employees Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Employees table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: No changes will occur to the source table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_employees: ['employeeid_pk_bk', 'name', 'position', 'storeid']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in df_employees:\", df_employees.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_dwh = df_employees\n",
    "\n",
    "windowSpec = Window.orderBy(\"employeeid_pk_bk\") \n",
    "employees_dwh = df_employees.withColumn(\"employeeid_pk_sk\", row_number().over(windowSpec))\n",
    "\n",
    "employees_dwh = employees_dwh.select(\n",
    "    \"employeeid_pk_sk\",  \n",
    "    \"employeeid_pk_bk\",  \n",
    "    \"storeid\",\n",
    "    \"name\",\n",
    "    \"position\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-------+---------------+-----------------+\n",
      "|employeeid_pk_sk|employeeid_pk_bk|storeid|           name|         position|\n",
      "+----------------+----------------+-------+---------------+-----------------+\n",
      "|               1|               1|     11|   DRAGO HORNIG|ASSISTANT MANAGER|\n",
      "|               2|               2|     31|   NOAH AZEVEDO|      STOCK CLERK|\n",
      "|               3|               3|     20|    JOHN BAILEY|          CASHIER|\n",
      "|               4|               4|      7|           唐旭|  SALES ASSOCIATE|\n",
      "|               5|               5|     26|LOURDES CABAÑAS|  SALES ASSOCIATE|\n",
      "+----------------+----------------+-------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_dwh.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employeeid_pk_sk: integer (nullable = false)\n",
      " |-- employeeid_pk_bk: integer (nullable = true)\n",
      " |-- storeid: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_dwh.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Transactiondb Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Date will be extracted from Transaction Date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_dwh = df_transactionsdb.select(to_date(\"Transaction Date\").alias(\"date\")).distinct()\n",
    "\n",
    "date_dwh = date_dwh.select(\n",
    "    col(\"date\"),\n",
    "    dayofmonth(\"date\").alias(\"day\"),\n",
    "    month(\"date\").alias(\"month\"),\n",
    "    date_format(\"date\", \"MMMM\").alias(\"month_name\"),\n",
    "    year(\"date\").alias(\"year\"),\n",
    "    dayofweek(\"date\").alias(\"day_of_week\"),            # 1=Sunday, 7=Saturday\n",
    "    date_format(\"date\", \"EEEE\").alias(\"day_name\"),    \n",
    "    weekofyear(\"date\").alias(\"week_of_year\"),\n",
    "    when(dayofweek(\"date\").isin(1, 7), lit(\"Yes\")).otherwise(lit(\"No\")).alias(\"is_weekend\"),\n",
    "    quarter(\"date\").alias(\"quarter\"),\n",
    "    date_format(\"date\", \"yyyy-MM\").alias(\"year_month\")\n",
    ")\n",
    "\n",
    "windowSpec = Window.orderBy(\"date\")\n",
    "date_dwh = date_dwh.withColumn(\"date_pk_sk\", row_number().over(windowSpec))\n",
    "\n",
    "date_dwh = date_dwh.select(\"date_pk_sk\", *[col for col in date_dwh.columns if col != \"date_pk_sk\"])\n",
    "\n",
    "date_dwh = date_dwh.select(\n",
    "    \"date_pk_sk\",  \n",
    "    \"date\",  \n",
    "    \"day\",\n",
    "    \"month\",\n",
    "    \"month_name\",\n",
    "    \"year\",\n",
    "    \"day_of_week\",\n",
    "    \"day_name\",\n",
    "    \"week_of_year\",\n",
    "    \"is_weekend\",\n",
    "    \"quarter\",\n",
    "    \"year_month\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+-----+----------+----+-----------+---------+------------+----------+-------+----------+\n",
      "|date_pk_sk|      date|day|month|month_name|year|day_of_week| day_name|week_of_year|is_weekend|quarter|year_month|\n",
      "+----------+----------+---+-----+----------+----+-----------+---------+------------+----------+-------+----------+\n",
      "|         1|2023-01-01|  1|    1|   January|2023|          1|   Sunday|          52|       Yes|      1|   2023-01|\n",
      "|         2|2023-01-02|  2|    1|   January|2023|          2|   Monday|           1|        No|      1|   2023-01|\n",
      "|         3|2023-01-03|  3|    1|   January|2023|          3|  Tuesday|           1|        No|      1|   2023-01|\n",
      "|         4|2023-01-04|  4|    1|   January|2023|          4|Wednesday|           1|        No|      1|   2023-01|\n",
      "|         5|2023-01-05|  5|    1|   January|2023|          5| Thursday|           1|        No|      1|   2023-01|\n",
      "+----------+----------+---+-----+----------+----+-----------+---------+------------+----------+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_dwh.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_pk_sk: integer (nullable = false)\n",
      " |-- date: date (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- month_name: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- day_name: string (nullable = true)\n",
      " |-- week_of_year: integer (nullable = true)\n",
      " |-- is_weekend: string (nullable = false)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- year_month: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_dwh.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transactions Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Transactions & Transcation Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Currency Symbol column is dropped. (Unnecessary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Add columns (Line, Total Line, Quantity) from Transactionlines Table to Transactionsdb Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transactionsdb = df_transactionsdb.join(\n",
    "    df_transactionlines, \n",
    "    \"Transaction ID\", \n",
    "    \"left\"\n",
    ").select(\n",
    "    df_transactionsdb[\"Transaction ID\"],\n",
    "    df_transactionsdb[\"Invoice ID\"],\n",
    "    df_transactionsdb[\"Transaction Date\"],\n",
    "    df_transactionsdb[\"Transaction Type\"],\n",
    "    df_transactionsdb[\"Payment Method\"],\n",
    "    df_transactionsdb[\"Invoice Total\"],\n",
    "    df_transactionlines[\"Line\"],\n",
    "    df_transactionlines[\"Line Total\"],  \n",
    "    df_transactionlines[\"Quantity\"]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------------+----------------+--------------+-------------+----+----------+--------+\n",
      "|Transaction ID|         Invoice ID|   Transaction Date|Transaction Type|Payment Method|Invoice Total|Line|Line Total|Quantity|\n",
      "+--------------+-------------------+-------------------+----------------+--------------+-------------+----+----------+--------+\n",
      "|        435824|INV-US-001-03650260|2023-10-04 11:50:00|            Sale|   Credit Card|        95.40|NULL|      NULL|    NULL|\n",
      "|        435825|INV-US-001-03650261|2023-10-04 16:26:00|            Sale|   Credit Card|        64.40|   2|     30.40|       1|\n",
      "|        435825|INV-US-001-03650261|2023-10-04 16:26:00|            Sale|   Credit Card|        64.40|   1|     34.00|       1|\n",
      "|        435821|INV-US-001-03650258|2023-10-04 19:28:00|            Sale|   Credit Card|        50.00|   1|     50.00|       1|\n",
      "|        435822|INV-US-001-03650259|2023-10-04 08:59:00|            Sale|   Credit Card|        27.50|NULL|      NULL|    NULL|\n",
      "+--------------+-------------------+-------------------+----------------+--------------+-------------+----+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transactionsdb.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-Join Transactionsdb & Transactionscsv Tables in one Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ensure consistent formatting of join keys\n",
    "df_transactionsdb = df_transactionsdb.withColumn(\"Invoice ID\", trim(col(\"Invoice ID\")))\n",
    "df_transactionscsv = df_transactionscsv.withColumn(\"Invoice ID\", trim(col(\"Invoice ID\")))\n",
    "\n",
    "# Optionally make case consistent (if needed)\n",
    "df_transactionsdb = df_transactionsdb.withColumn(\"Invoice ID\", lower(col(\"Invoice ID\")))\n",
    "df_transactionscsv = df_transactionscsv.withColumn(\"Invoice ID\", lower(col(\"Invoice ID\")))\n",
    "\n",
    "# Verify data types match (both should be string)\n",
    "df_transactionsdb = df_transactionsdb.withColumn(\"Invoice ID\", col(\"Invoice ID\").cast(\"string\"))\n",
    "df_transactionscsv = df_transactionscsv.withColumn(\"Invoice ID\", col(\"Invoice ID\").cast(\"string\"))\n",
    "\n",
    "# Perform the join - using left join to preserve all CSV records (which contain Line/Quantity/Line Total)\n",
    "transactions_dwh = df_transactionscsv.join(\n",
    "    df_transactionsdb,\n",
    "    [\"Invoice ID\"],\n",
    "    how=\"left\"\n",
    ").select(\n",
    "    coalesce(df_transactionsdb[\"Transaction ID\"], lit(0)).alias(\"Transaction ID\").alias(\"transactionid\"),\n",
    "    col(\"Invoice ID\").alias(\"invoiceid\"),\n",
    "    coalesce(df_transactionsdb[\"Transaction Type\"], df_transactionscsv[\"Transaction Type\"]).alias(\"transactiontype\"),\n",
    "    df_transactionscsv[\"Quantity\"].alias(\"quantity\"),  # Always take from CSV \n",
    "    df_transactionscsv[\"Line Total\"].alias(\"line\"),  # Always take from CSV\n",
    "    coalesce(df_transactionsdb[\"Payment Method\"], df_transactionscsv[\"Payment Method\"]).alias(\"paymentmethod\"),\n",
    "    coalesce(df_transactionsdb[\"Invoice Total\"], df_transactionscsv[\"Invoice Total\"]).alias(\"invoicetotal\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-Clean TransactionsDWH Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transactionid',\n",
       " 'invoiceid',\n",
       " 'transactiontype',\n",
       " 'quantity',\n",
       " 'line',\n",
       " 'paymentmethod',\n",
       " 'invoicetotal']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_dwh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+---------------+--------+------+-------------+------------+\n",
      "|transactionid|          invoiceid|transactiontype|quantity|  line|paymentmethod|invoicetotal|\n",
      "+-------------+-------------------+---------------+--------+------+-------------+------------+\n",
      "|            0|inv-us-004-01360995|           Sale|       1| 54.50|  Credit Card|       54.50|\n",
      "|            0|inv-us-004-01361417|           Sale|       1| 45.50|  Credit Card|       45.50|\n",
      "|            0|inv-us-004-01361567|           Sale|       3|130.50|         Cash|      257.50|\n",
      "|       544406|ret-us-004-01358472|         Return|       1|-42.50|  Credit Card|      -98.50|\n",
      "|       544405|ret-us-004-01358472|         Return|       1|-42.50|  Credit Card|      -98.50|\n",
      "+-------------+-------------------+---------------+--------+------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_dwh.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transactionid: integer (nullable = false)\n",
      " |-- invoiceid: string (nullable = true)\n",
      " |-- transactiontype: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- line: decimal(10,2) (nullable = true)\n",
      " |-- paymentmethod: string (nullable = true)\n",
      " |-- invoicetotal: decimal(10,2) (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_dwh.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data into CSVs Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = date_dwh.toPandas()\n",
    "pandas_df.to_csv(r\"P:/Career/Data Engineering/ITI-DE/Graduation Project/Data/Data Destinations/Date.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = customers_dwh.toPandas()\n",
    "pandas_df.to_csv(r\"P:/Career/Data Engineering/ITI-DE/Graduation Project/Data/Data Destinations/Customers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = discounts_dwh.toPandas()\n",
    "pandas_df.to_csv(r\"P:/Career/Data Engineering/ITI-DE/Graduation Project/Data/Data Destinations/Discounts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = products_dwh.toPandas()\n",
    "pandas_df.to_csv(r\"P:/Career/Data Engineering/ITI-DE/Graduation Project/Data/Data Destinations/Products.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = stores_dwh.toPandas()\n",
    "pandas_df.to_csv(r\"P:/Career/Data Engineering/ITI-DE/Graduation Project/Data/Data Destinations/Stores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = employees_dwh.toPandas()\n",
    "pandas_df.to_csv(r\"P:/Career/Data Engineering/ITI-DE/Graduation Project/Data/Data Destinations/Employees.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = transactions_dwh.toPandas()\n",
    "pandas_df.to_csv(r\"P:/Career/Data Engineering/ITI-DE/Graduation Project/Data/Data Destinations/Transactions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
